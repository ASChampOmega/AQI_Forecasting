{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe35e25",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:14.288042Z",
     "iopub.status.busy": "2025-04-12T00:37:14.287620Z",
     "iopub.status.idle": "2025-04-12T00:37:25.551272Z",
     "shell.execute_reply": "2025-04-12T00:37:25.550143Z"
    },
    "papermill": {
     "duration": 11.275419,
     "end_time": "2025-04-12T00:37:25.553378",
     "exception": false,
     "start_time": "2025-04-12T00:37:14.277959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebrae\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "\n",
    "import os\n",
    "\n",
    "# from polire import IDW\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "import pickle as pkl\n",
    "import itertools\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498ba799",
   "metadata": {
    "papermill": {
     "duration": 0.007155,
     "end_time": "2025-04-12T00:37:25.567901",
     "exception": false,
     "start_time": "2025-04-12T00:37:25.560746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f242c93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:25.584238Z",
     "iopub.status.busy": "2025-04-12T00:37:25.583486Z",
     "iopub.status.idle": "2025-04-12T00:37:25.588228Z",
     "shell.execute_reply": "2025-04-12T00:37:25.587216Z"
    },
    "papermill": {
     "duration": 0.014338,
     "end_time": "2025-04-12T00:37:25.589945",
     "exception": false,
     "start_time": "2025-04-12T00:37:25.575607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    evaluation_time_gap = 1\n",
    "    convert_numpy = False\n",
    "    target_list = ['pm2_5', 'pm10']\n",
    "    features = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66560ff",
   "metadata": {
    "papermill": {
     "duration": 0.006307,
     "end_time": "2025-04-12T00:37:25.603176",
     "exception": false,
     "start_time": "2025-04-12T00:37:25.596869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Basic Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11df6c49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:25.618959Z",
     "iopub.status.busy": "2025-04-12T00:37:25.618588Z",
     "iopub.status.idle": "2025-04-12T00:37:25.978191Z",
     "shell.execute_reply": "2025-04-12T00:37:25.977167Z"
    },
    "papermill": {
     "duration": 0.369699,
     "end_time": "2025-04-12T00:37:25.979941",
     "exception": false,
     "start_time": "2025-04-12T00:37:25.610242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2021-01-07 00:00:00'), Timestamp('2020-11-01 00:00:00'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/airdelhi-tabularengineering/tabular_data.csv')\n",
    "\n",
    "df = df.drop(columns = 'Unnamed: 0')\n",
    "df['date_value'] = pd.to_datetime(df['date_value'])\n",
    "\n",
    "dates = pd.to_datetime([df['date_value'].min(), df['date_value'].max()])\n",
    "\n",
    "max_train_date = dates.min() + (dates.max() - dates.min()) * 0.75\n",
    "max_train_date = max_train_date.floor(\"D\")\n",
    "min_train_date = df['date_value'].min()\n",
    "max_date = df['date_value'].max().floor(\"D\")\n",
    "\n",
    "# metrics_dict = {\n",
    "#     'MSE': mean_squared_error, \n",
    "#     'r2 score': r2_score, \n",
    "#     'MAE': mean_absolute_error,\n",
    "# }\n",
    "\n",
    "target_list = CFG.target_list\n",
    "\n",
    "features = ['date_value', 'timeOfDay', 'lat', 'lon', 'day_of_week', 'distance', 'bus_count']\n",
    "\n",
    "CFG.base_features = ['timeOfDay', 'lat', 'lon', 'day_of_week', 'distance', 'bus_count']\n",
    "CFG.features = CFG.base_features\n",
    "\n",
    "max_train_date, min_train_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d5f527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:25.995433Z",
     "iopub.status.busy": "2025-04-12T00:37:25.995033Z",
     "iopub.status.idle": "2025-04-12T00:37:26.035177Z",
     "shell.execute_reply": "2025-04-12T00:37:26.034245Z"
    },
    "papermill": {
     "duration": 0.050029,
     "end_time": "2025-04-12T00:37:26.037165",
     "exception": false,
     "start_time": "2025-04-12T00:37:25.987136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df[['timeOfDay', 'lat', 'lon', 'day_of_week', 'distance', 'bus_count']] = scaler.fit_transform(\n",
    "    df[['timeOfDay', 'lat', 'lon', 'day_of_week', 'distance', 'bus_count']]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba36d4c",
   "metadata": {
    "papermill": {
     "duration": 0.006332,
     "end_time": "2025-04-12T00:37:26.050444",
     "exception": false,
     "start_time": "2025-04-12T00:37:26.044112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Basic Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12efee1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:26.065096Z",
     "iopub.status.busy": "2025-04-12T00:37:26.064673Z",
     "iopub.status.idle": "2025-04-12T00:37:26.069141Z",
     "shell.execute_reply": "2025-04-12T00:37:26.068167Z"
    },
    "papermill": {
     "duration": 0.01366,
     "end_time": "2025-04-12T00:37:26.070762",
     "exception": false,
     "start_time": "2025-04-12T00:37:26.057102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_df(df, features=None):\n",
    "    if features is None:\n",
    "        return df[CFG.features]\n",
    "    else:\n",
    "        return df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900d2245",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:26.085538Z",
     "iopub.status.busy": "2025-04-12T00:37:26.085211Z",
     "iopub.status.idle": "2025-04-12T00:37:26.092284Z",
     "shell.execute_reply": "2025-04-12T00:37:26.091340Z"
    },
    "papermill": {
     "duration": 0.016535,
     "end_time": "2025-04-12T00:37:26.094062",
     "exception": false,
     "start_time": "2025-04-12T00:37:26.077527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class AQIClassifier:\n",
    "    def __init__(self, pollutant):\n",
    "        if pollutant == 'pm2_5':\n",
    "            self.thresholds_ = [0, 30, 60, 90, 120, 250, np.inf]\n",
    "        elif pollutant == 'pm10':\n",
    "            self.thresholds_ = [0, 50, 100, 250, 350, 430, np.inf]\n",
    "        else:\n",
    "            raise ValueError(\"pollutant must be 'pm2_5' or 'pm10'\")\n",
    "        self.pollutant = pollutant\n",
    "        self.bin_labels_ = ['Good', 'Satisfactory', 'Moderately Polluted', 'Poor', 'Very Poor', 'Severe']\n",
    "\n",
    "    def bin(self, values):\n",
    "\n",
    "        values = np.asarray(values)\n",
    "        return np.digitize(values, self.thresholds_, right=True) - 1\n",
    "\n",
    "    def __call__(self, y_true, y_pred, return_labels=False):\n",
    "        y_true_bins = self.bin(y_true)\n",
    "        y_pred_bins = self.bin(y_pred)\n",
    "\n",
    "        acc = accuracy_score(y_true_bins, y_pred_bins)\n",
    "\n",
    "        if return_labels:\n",
    "            return acc, (y_true_bins, y_pred_bins)\n",
    "        return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be278d20",
   "metadata": {
    "papermill": {
     "duration": 0.006629,
     "end_time": "2025-04-12T00:37:26.107653",
     "exception": false,
     "start_time": "2025-04-12T00:37:26.101024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get Model Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d9f09dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:26.122483Z",
     "iopub.status.busy": "2025-04-12T00:37:26.122142Z",
     "iopub.status.idle": "2025-04-12T00:37:26.129923Z",
     "shell.execute_reply": "2025-04-12T00:37:26.128817Z"
    },
    "papermill": {
     "duration": 0.01719,
     "end_time": "2025-04-12T00:37:26.131622",
     "exception": false,
     "start_time": "2025-04-12T00:37:26.114432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataSplitter:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        dataset, \n",
    "        min_date, \n",
    "        max_date, \n",
    "        max_lookback=None,\n",
    "        min_lookback=None,\n",
    "    ):\n",
    "        # self.X = dataset[CFG.features if features is None else features]\n",
    "        \n",
    "        # self.target = target\n",
    "        # self.y = dataset[target]\n",
    "        \n",
    "        self.df = dataset\n",
    "        \n",
    "        self.min_train_date = min_date\n",
    "        self.max_train_date = max_date\n",
    "        self.df_max_date = self.df['date_value'].max()\n",
    "\n",
    "        self.max_lookback = max_lookback\n",
    "        self.min_lookback = min_lookback\n",
    "    \n",
    "    def get_train_test_split(self):\n",
    "        df = self.df.copy()\n",
    "        df = df[df['date_value'] >= self.min_train_date]\n",
    "        d = self.max_train_date + timedelta(days = 1)\n",
    "\n",
    "        splits = {}\n",
    "        \n",
    "        while d < self.df_max_date:\n",
    "            train_temp = df[df['date_value'] <= d]\n",
    "            if self.max_lookback is not None:\n",
    "                train_temp = train_temp[train_temp['date_value'] > d - timedelta(\n",
    "                    days = self.max_lookback)]\n",
    "\n",
    "            if self.min_lookback is not None:\n",
    "                train_temp1 = train_temp[train_temp['date_value'] <= d - timedelta(\n",
    "                    days = self.min_lookback)]\n",
    "                if len(train_temp1) > 200:\n",
    "                    train_temp = train_temp1\n",
    "            \n",
    "            train_indices = train_temp.index\n",
    "            test_indices = df[df['date_value'] == d + timedelta(days=1)].index\n",
    "\n",
    "            splits[d] = {\n",
    "                'train': train_indices,\n",
    "                'test' : test_indices\n",
    "            }\n",
    "            \n",
    "            d = d + timedelta(days = CFG.evaluation_time_gap)\n",
    "\n",
    "        return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b078bd1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:26.147144Z",
     "iopub.status.busy": "2025-04-12T00:37:26.146737Z",
     "iopub.status.idle": "2025-04-12T00:37:26.316109Z",
     "shell.execute_reply": "2025-04-12T00:37:26.314850Z"
    },
    "papermill": {
     "duration": 0.179603,
     "end_time": "2025-04-12T00:37:26.318177",
     "exception": false,
     "start_time": "2025-04-12T00:37:26.138574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-08 00:00:00 2021-01-08 00:00:00\n",
      "2021-01-08 00:00:00 [Timestamp('2021-01-09 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "data_splitter = DataSplitter(df, min_train_date, max_train_date)\n",
    "data_indices = data_splitter.get_train_test_split()\n",
    "\n",
    "# Testing:\n",
    "test_date = list(data_indices.keys())[0]\n",
    "train_indices, test_indices = list(data_indices[test_date].values())\n",
    "# test_date, list(data_indices.keys())\n",
    "train_df_1 = df.iloc[train_indices]\n",
    "print(test_date, sorted(train_df_1.date_value.unique())[-1])\n",
    "\n",
    "test_df_1 = df.iloc[test_indices]\n",
    "print(test_date, sorted(test_df_1.date_value.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7852d8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:26.334187Z",
     "iopub.status.busy": "2025-04-12T00:37:26.333836Z",
     "iopub.status.idle": "2025-04-12T00:37:26.483086Z",
     "shell.execute_reply": "2025-04-12T00:37:26.481955Z"
    },
    "papermill": {
     "duration": 0.159359,
     "end_time": "2025-04-12T00:37:26.485017",
     "exception": false,
     "start_time": "2025-04-12T00:37:26.325658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-08 00:00:00 [Timestamp('2021-01-06 00:00:00'), Timestamp('2021-01-07 00:00:00'), Timestamp('2021-01-08 00:00:00')]\n",
      "2021-01-08 00:00:00 [Timestamp('2021-01-09 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "data_splitter = DataSplitter(df, min_train_date, max_train_date, max_lookback=3)\n",
    "data_indices = data_splitter.get_train_test_split()\n",
    "\n",
    "# Testing:\n",
    "test_date = list(data_indices.keys())[0]\n",
    "train_indices, test_indices = list(data_indices[test_date].values())\n",
    "# test_date, list(data_indices.keys())\n",
    "train_df_1 = df.iloc[train_indices]\n",
    "print(test_date, sorted(train_df_1.date_value.unique()))\n",
    "\n",
    "test_df_1 = df.iloc[test_indices]\n",
    "print(test_date, sorted(test_df_1.date_value.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf7809a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:26.500965Z",
     "iopub.status.busy": "2025-04-12T00:37:26.500601Z",
     "iopub.status.idle": "2025-04-12T00:37:26.882944Z",
     "shell.execute_reply": "2025-04-12T00:37:26.881419Z"
    },
    "papermill": {
     "duration": 0.392642,
     "end_time": "2025-04-12T00:37:26.885267",
     "exception": false,
     "start_time": "2025-04-12T00:37:26.492625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-02 00:00:00 [Timestamp('2020-11-01 00:00:00'), Timestamp('2020-11-02 00:00:00')]\n",
      "2020-11-02 00:00:00 [Timestamp('2020-11-03 00:00:00')]\n",
      "2020-11-01 00:00:00 2020-11-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "data_splitter = DataSplitter(df, min_train_date, min_train_date, max_lookback=2)\n",
    "data_indices = data_splitter.get_train_test_split()\n",
    "\n",
    "# Testing:\n",
    "test_date = list(data_indices.keys())[0]\n",
    "train_indices, test_indices = list(data_indices[test_date].values())\n",
    "# test_date, list(data_indices.keys())\n",
    "train_df_1 = df.iloc[train_indices]\n",
    "print(test_date, sorted(train_df_1.date_value.unique()))\n",
    "\n",
    "test_df_1 = df.iloc[test_indices]\n",
    "print(test_date, sorted(test_df_1.date_value.unique()))\n",
    "\n",
    "print(min_train_date, df.date_value.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3557d2",
   "metadata": {
    "papermill": {
     "duration": 0.008385,
     "end_time": "2025-04-12T00:37:26.901756",
     "exception": false,
     "start_time": "2025-04-12T00:37:26.893371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d03fd9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:26.921422Z",
     "iopub.status.busy": "2025-04-12T00:37:26.921087Z",
     "iopub.status.idle": "2025-04-12T00:37:26.930896Z",
     "shell.execute_reply": "2025-04-12T00:37:26.929696Z"
    },
    "papermill": {
     "duration": 0.019745,
     "end_time": "2025-04-12T00:37:26.932766",
     "exception": false,
     "start_time": "2025-04-12T00:37:26.913021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_class,\n",
    "        params=None,\n",
    "        target=\"pm2_5\",\n",
    "        features=None,\n",
    "    ):\n",
    "        self.model_class = model_class\n",
    "        \n",
    "        if params is None:\n",
    "            self.params = {}\n",
    "        else:\n",
    "            self.params = params\n",
    "\n",
    "        self.max_train_date = None\n",
    "        self.target = target\n",
    "        if features is None:\n",
    "            features = CFG.features\n",
    "\n",
    "        self.features = features\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        model = self.model_class(**self.params)\n",
    "        # print(X.columns, CFG.features)\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "\n",
    "    def predict(self, X):\n",
    "        model = self.split_models[self.max_train_date]\n",
    "        return model.predict(X)\n",
    "\n",
    "    def get_df_from_split(self, df, split, split_type='train'):\n",
    "        X = df.iloc[split[split_type]].copy()\n",
    "        y = np.array(X[self.target])\n",
    "        X = clean_df(X, features=self.features)\n",
    "        return X, y\n",
    "\n",
    "    def fit_on_splits(self, df, splits):\n",
    "        self.split_models = {}\n",
    "        \n",
    "        for d, split in splits.items():\n",
    "            X, y = self.get_df_from_split(df, split)\n",
    "            self.split_models[d] = self.fit(X, y)\n",
    "\n",
    "    def predict_on_splits(self, df, splits, train=False):\n",
    "        model_predictions = {}\n",
    "        if train:\n",
    "            train = 'train'\n",
    "        else:\n",
    "            train= 'test'\n",
    "        \n",
    "        for d, split in splits.items():\n",
    "            X, y = self.get_df_from_split(df, split, split_type=train)\n",
    "            model_predictions[d] = {\n",
    "                'pred': self.split_models[d].predict(X),\n",
    "                'true': y,\n",
    "                'index': X.index\n",
    "            }\n",
    "        \n",
    "        return model_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde0d6cc",
   "metadata": {
    "papermill": {
     "duration": 0.00658,
     "end_time": "2025-04-12T00:37:26.946597",
     "exception": false,
     "start_time": "2025-04-12T00:37:26.940017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc511a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:26.962072Z",
     "iopub.status.busy": "2025-04-12T00:37:26.961643Z",
     "iopub.status.idle": "2025-04-12T00:37:26.977361Z",
     "shell.execute_reply": "2025-04-12T00:37:26.976063Z"
    },
    "papermill": {
     "duration": 0.026147,
     "end_time": "2025-04-12T00:37:26.979602",
     "exception": false,
     "start_time": "2025-04-12T00:37:26.953455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        min_date,\n",
    "        max_date,\n",
    "        target,\n",
    "        metrics_dict,\n",
    "        max_lookback=None\n",
    "    ):\n",
    "        self.df_splitter = DataSplitter(dataset, min_date, max_date, max_lookback=max_lookback)\n",
    "        self.metrics_dict = metrics_dict\n",
    "        self.dataset = dataset\n",
    "        self.target = target\n",
    "\n",
    "        self.splits = self.df_splitter.get_train_test_split()\n",
    "\n",
    "    def fit_predict(self, model):\n",
    "        model.fit_on_splits(self.dataset, self.splits)\n",
    "        train_preds = model.predict_on_splits(self.dataset, self.splits, train=True)\n",
    "        test_preds = model.predict_on_splits(self.dataset, self.splits, train=False)\n",
    "        return train_preds, test_preds\n",
    "\n",
    "    def evaluate_metrics(self, y_true, y_pred):\n",
    "        values = {}\n",
    "        for d, metric in self.metrics_dict.items():\n",
    "            values[d] = metric(y_true, y_pred)\n",
    "        return values\n",
    "\n",
    "    def merge_evaluations(self, evaluations):\n",
    "        merged_evaluations = {}\n",
    "        for d, evaluation in evaluations.items():\n",
    "            if d in ['aggregated', 'aggregated_train']:\n",
    "                continue\n",
    "            if len(merged_evaluations) == 0:\n",
    "                merged_evaluations = {\n",
    "                    k : [v]\n",
    "                    for k, v in evaluation.items()\n",
    "                }\n",
    "            else:\n",
    "                for k, v in evaluation.items():\n",
    "                    merged_evaluations[k].append(v)\n",
    "\n",
    "        merged_evaluations['aggregated'] = evaluations['aggregated']\n",
    "        # merged_evaluations['aggregated_train'] = evaluations['aggregated_train']\n",
    "        \n",
    "        return merged_evaluations\n",
    "\n",
    "    def save(self, model, evaluations, model_name):\n",
    "        with open(f'{model_name}_evaluation.json', 'w') as f:\n",
    "            json.dump(evaluations, f)\n",
    "\n",
    "        with open(f'{model_name}_model.pkl', 'wb') as f:\n",
    "            pkl.dump(model, f)\n",
    "\n",
    "    def print(self, train_evaluations, test_evaluations):\n",
    "        print(f\"\"\"Train PM {self.target}: R2 Score {train_evaluations['aggregated']['r2 score']}, \n",
    "               RMSE {np.sqrt(train_evaluations['aggregated']['MSE'])}\n",
    "               MAE  {train_evaluations['aggregated']['MAE']}\n",
    "               Acc  {train_evaluations['aggregated']['Accuracy']}\n",
    "        \"\"\")\n",
    "        print(f\"\"\"Test PM {self.target}: R2 Score {test_evaluations['aggregated']['r2 score']}, \n",
    "              RMSE {np.sqrt(test_evaluations['aggregated']['MSE'])}\n",
    "              MAE  {test_evaluations['aggregated']['MAE']}\n",
    "              Acc  {test_evaluations['aggregated']['Accuracy']}\n",
    "        \"\"\")\n",
    "        \n",
    "\n",
    "    def evaluate(self, model, daily=False, save=True, model_name=None, verbose=True):\n",
    "        train_preds, test_preds = self.fit_predict(model)\n",
    "\n",
    "        train_metrics = {}\n",
    "        train_pred_full = []\n",
    "        train_full = []\n",
    "        for d, v in train_preds.items():\n",
    "            train_metrics[d] = self.evaluate_metrics(v['true'], v['pred'])\n",
    "            train_pred_full.append(v['pred'])\n",
    "            train_full.append(v['true'])\n",
    "\n",
    "        train_pred_full = np.concatenate(train_pred_full)\n",
    "        train_full = np.concatenate(train_full)\n",
    "        \n",
    "\n",
    "        test_metrics = {}\n",
    "        test_pred_full = []\n",
    "        test_full = []\n",
    "        index_full = []\n",
    "        for d, v in test_preds.items():\n",
    "            test_metrics[d] = self.evaluate_metrics(v['true'], v['pred'])\n",
    "            test_pred_full.append(v['pred'])\n",
    "            test_full.append(v['true'])\n",
    "            index_full.append(v['index'])\n",
    "        \n",
    "        test_pred_full = np.concatenate(test_pred_full)\n",
    "        test_full = np.concatenate(test_full)\n",
    "        index_full = np.concatenate(index_full)\n",
    "\n",
    "        train_metrics['aggregated'] = self.evaluate_metrics(train_full, train_pred_full)\n",
    "        test_metrics['aggregated'] = self.evaluate_metrics(test_full, test_pred_full)\n",
    "        \n",
    "        if not daily:\n",
    "            train_metrics, test_metrics = self.merge_evaluations(train_metrics), self.merge_evaluations(test_metrics)\n",
    "\n",
    "        if save:\n",
    "            self.save(model, {'train':train_metrics,'test':test_metrics}, model_name)\n",
    "\n",
    "        if verbose:\n",
    "            self.print(train_metrics, test_metrics)\n",
    "        \n",
    "        return train_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9054fb4",
   "metadata": {
    "papermill": {
     "duration": 0.006805,
     "end_time": "2025-04-12T00:37:26.993800",
     "exception": false,
     "start_time": "2025-04-12T00:37:26.986995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Additional Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcaa30f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:27.009033Z",
     "iopub.status.busy": "2025-04-12T00:37:27.008524Z",
     "iopub.status.idle": "2025-04-12T00:37:27.017851Z",
     "shell.execute_reply": "2025-04-12T00:37:27.016570Z"
    },
    "papermill": {
     "duration": 0.0192,
     "end_time": "2025-04-12T00:37:27.019923",
     "exception": false,
     "start_time": "2025-04-12T00:37:27.000723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "class IDW:\n",
    "\n",
    "    def __init__(self, leafsize, power = 3, k = 10):\n",
    "        self.leafsize = leafsize\n",
    "        self.power = power\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        # self.y = y.values\n",
    "        self.y = y\n",
    "\n",
    "        self.tree = cKDTree(self.X.values, leafsize=self.leafsize)\n",
    "\n",
    "    def predict(self, test_df):\n",
    "        X_test = test_df.values\n",
    "        \n",
    "        distances, indices = self.tree.query(X_test, k=self.k, workers=-1)\n",
    "        distances = np.maximum(distances, 1e-10)\n",
    "        \n",
    "        weights = 1 / (distances ** self.power)\n",
    "        weights /= np.sum(weights, axis=1, keepdims=True)\n",
    "        \n",
    "        interpolated_values = np.sum(weights * self.y[indices], axis=1)\n",
    "        \n",
    "        return interpolated_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f3a35a",
   "metadata": {
    "papermill": {
     "duration": 0.007105,
     "end_time": "2025-04-12T00:37:27.034288",
     "exception": false,
     "start_time": "2025-04-12T00:37:27.027183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Lagged Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63ebc07a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:27.050188Z",
     "iopub.status.busy": "2025-04-12T00:37:27.049700Z",
     "iopub.status.idle": "2025-04-12T00:37:27.066343Z",
     "shell.execute_reply": "2025-04-12T00:37:27.064627Z"
    },
    "papermill": {
     "duration": 0.029456,
     "end_time": "2025-04-12T00:37:27.071072",
     "exception": false,
     "start_time": "2025-04-12T00:37:27.041616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_lag_features(df, lags = [1]):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    added_features = []\n",
    "    for l in lags:\n",
    "        df[f'pm2_5_lag_{l}'] = df.groupby(\n",
    "            ['timeOfDay', 'lat', 'lon'])['pm2_5'].shift(l)\n",
    "        df[f'pm10_lag_{l}'] = df.groupby(\n",
    "            ['timeOfDay', 'lat', 'lon'])['pm10'].shift(l)\n",
    "\n",
    "        added_features.append(f'pm2_5_lag_{l}')\n",
    "        added_features.append(f'pm10_lag_{l}')\n",
    "\n",
    "        # .reset_index(drop=False)\n",
    "        \n",
    "        # shifted_pm25 = df.groupby(['timeOfDay', 'lat', 'lon'])['pm2_5'].shift(1).reset_index(drop=False)\n",
    "        # shifted_pm10 = df.groupby(['timeOfDay', 'lat', 'lon'])['pm10'].shift(1).reset_index(drop=False)\n",
    "\n",
    "        # shifted_pm25 = shifted_pm25.rename(columns = {'pm2_5' : f'pm2_5_lag_{l}'})\n",
    "        # shifted_pm10 = shifted_pm10.rename(columns = {'pm10' : f'pm10_lag_{l}'})\n",
    "\n",
    "        # df = pd.merge(df, shifted_pm25, how = 'outer', on =  ['timeOfDay', 'lat', 'lon'])\n",
    "        # df = pd.merge(df, shifted_pm10, how = 'outer', on =  ['timeOfDay', 'lat', 'lon'])\n",
    "\n",
    "\n",
    "        df.sort_values(by=[\"lat\", \"lon\", \"date_value\"], inplace=True)\n",
    "\n",
    "    # Group by latitude and longitude\n",
    "    grouped = df.groupby([\"lat\", \"lon\"])\n",
    "\n",
    "    # Function to fill NaN values based on previous mean\n",
    "    def fill_na_with_previous_mean(group):\n",
    "        for col in group.columns:\n",
    "            if col not in [\"date_value\", \"lat\", \"lon\"]:\n",
    "                group[col] = group[col].astype(float)  # Ensure numeric columns\n",
    "                group[col] = group[col].fillna(group[col].expanding().mean().shift())  # Previous days' mean\n",
    "                \n",
    "                # If still NaN (first row), replace with overall mean\n",
    "                overall_mean = df[col].mean(skipna=True)\n",
    "                group[col] = group[col].fillna(overall_mean)\n",
    "        return group\n",
    "\n",
    "    # Apply the function to each group\n",
    "    df = grouped.apply(fill_na_with_previous_mean)\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df = df.sort_values(by = ['date_value', 'timeOfDay', 'lat', 'lon'])\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    CFG.features += added_features\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "133b3ebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:27.087151Z",
     "iopub.status.busy": "2025-04-12T00:37:27.086681Z",
     "iopub.status.idle": "2025-04-12T00:37:34.041694Z",
     "shell.execute_reply": "2025-04-12T00:37:34.040284Z"
    },
    "papermill": {
     "duration": 6.965081,
     "end_time": "2025-04-12T00:37:34.043539",
     "exception": false,
     "start_time": "2025-04-12T00:37:27.078458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-e4098ddd2843>:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = grouped.apply(fill_na_with_previous_mean)\n"
     ]
    }
   ],
   "source": [
    "df = add_lag_features(df, lags = [1, 2, 3, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4df1c1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:34.059149Z",
     "iopub.status.busy": "2025-04-12T00:37:34.058717Z",
     "iopub.status.idle": "2025-04-12T00:37:34.067224Z",
     "shell.execute_reply": "2025-04-12T00:37:34.066094Z"
    },
    "papermill": {
     "duration": 0.018368,
     "end_time": "2025-04-12T00:37:34.068963",
     "exception": false,
     "start_time": "2025-04-12T00:37:34.050595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IDW Interpolation\n",
    "\n",
    "def idw_interpolation(df, idw, lags):\n",
    "    df = df.copy()\n",
    "    df['lat'] = df['lat'] * 50\n",
    "    df['lon'] = df['lon'] * 50\n",
    "    \n",
    "    target = idw.target\n",
    "    added_features = []\n",
    "    \n",
    "    for lag in lags:\n",
    "        df_splitter = DataSplitter(\n",
    "            df.copy(), min_train_date, min_train_date+timedelta(days=1), \n",
    "            max_lookback=lag+1, min_lookback=lag-1\n",
    "        )\n",
    "        splits = df_splitter.get_train_test_split()\n",
    "    \n",
    "        idw.fit_on_splits(df, splits)\n",
    "        preds = idw.predict_on_splits(df, splits)\n",
    "\n",
    "        test_pred_full = []\n",
    "        test_full = []\n",
    "        index_full = []\n",
    "        \n",
    "        for d, v in preds.items():\n",
    "            test_pred_full.append(v['pred'])\n",
    "            test_full.append(v['true'])\n",
    "            index_full.append(v['index'])\n",
    "        \n",
    "        test_pred_full = np.concatenate(test_pred_full)\n",
    "        test_full = np.concatenate(test_full)\n",
    "        index_full = np.concatenate(index_full)\n",
    "\n",
    "        new_df = pd.DataFrame({\n",
    "            # f'test_lag_{lag}': test_full,\n",
    "            f'idw_lag_{lag}_{target}': test_pred_full,\n",
    "        }, index = index_full)\n",
    "        \n",
    "        df = df.merge(new_df, left_index=True, right_index=True, how='outer')\n",
    "        # df[f'test_lag_{lag}'] = df[f'test_lag_{lag}'].fillna(df[f'test_lag_{lag}'].expanding().mean())\n",
    "        df[f'idw_lag_{lag}_{target}'] = df[f'idw_lag_{lag}_{target}'].fillna(df[f'idw_lag_{lag}_{target}'].expanding().mean())\n",
    "        \n",
    "        df = df.bfill()\n",
    "\n",
    "        added_features.append(f'idw_lag_{lag}_{target}')\n",
    "\n",
    "    df['lat'] = df['lat'] / 50\n",
    "    df['lon'] = df['lon'] / 50\n",
    "\n",
    "    CFG.features = CFG.features + added_features\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a9409cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:34.084424Z",
     "iopub.status.busy": "2025-04-12T00:37:34.084056Z",
     "iopub.status.idle": "2025-04-12T00:37:40.742887Z",
     "shell.execute_reply": "2025-04-12T00:37:40.741638Z"
    },
    "papermill": {
     "duration": 6.668871,
     "end_time": "2025-04-12T00:37:40.744843",
     "exception": false,
     "start_time": "2025-04-12T00:37:34.075972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pm2_5\n",
    "\n",
    "idw_model = Model(\n",
    "    IDW,\n",
    "    params={'leafsize': 50, 'power': 3, 'k': 3}\n",
    ")\n",
    "\n",
    "# idw_model = Model(\n",
    "#     RandomForestRegressor,\n",
    "# )\n",
    "\n",
    "df = idw_interpolation(df, idw_model, lags = [1])\n",
    "df = idw_interpolation(df, idw_model, lags = [2])\n",
    "df = idw_interpolation(df, idw_model, lags = [3])\n",
    "df = idw_interpolation(df, idw_model, lags = [7])\n",
    "\n",
    "# print(np.sqrt(mean_squared_error(df['test_lag_1'], df['idw_lag_1_pm2_5'])))\n",
    "# print(np.sqrt(mean_squared_error(df['test_lag_2'], df['idw_lag_2_pm2_5'])))\n",
    "# print(np.sqrt(mean_squared_error(df['test_lag_3'], df['idw_lag_3_pm2_5'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6131482e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:40.760261Z",
     "iopub.status.busy": "2025-04-12T00:37:40.759897Z",
     "iopub.status.idle": "2025-04-12T00:37:53.853069Z",
     "shell.execute_reply": "2025-04-12T00:37:53.851774Z"
    },
    "papermill": {
     "duration": 13.103261,
     "end_time": "2025-04-12T00:37:53.855329",
     "exception": false,
     "start_time": "2025-04-12T00:37:40.752068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pm10\n",
    "\n",
    "idw_model = Model(\n",
    "    IDW,\n",
    "    params={'leafsize': 50, 'power': 3, 'k': 3},\n",
    "    target='pm10'\n",
    ")\n",
    "\n",
    "# idw_model = Model(\n",
    "#     RandomForestRegressor,\n",
    "#     target='pm10'\n",
    "# )\n",
    "\n",
    "df = idw_interpolation(df, idw_model, lags = [1])\n",
    "df = idw_interpolation(df, idw_model, lags = [2])\n",
    "df = idw_interpolation(df, idw_model, lags = [3])\n",
    "df = idw_interpolation(df, idw_model, lags = [7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf1237a",
   "metadata": {
    "papermill": {
     "duration": 0.006764,
     "end_time": "2025-04-12T00:37:53.869871",
     "exception": false,
     "start_time": "2025-04-12T00:37:53.863107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b81cf68c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:53.885088Z",
     "iopub.status.busy": "2025-04-12T00:37:53.884736Z",
     "iopub.status.idle": "2025-04-12T00:37:53.958392Z",
     "shell.execute_reply": "2025-04-12T00:37:53.957100Z"
    },
    "papermill": {
     "duration": 0.083559,
     "end_time": "2025-04-12T00:37:53.960335",
     "exception": false,
     "start_time": "2025-04-12T00:37:53.876776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_sparse_data(df, count):\n",
    "    df = df.copy()\n",
    "    lat_lon_pairs = df.groupby(by=['lat', 'lon'])['pm2_5'].count().reset_index()\n",
    "    lat_lon_pairs = lat_lon_pairs[lat_lon_pairs['pm2_5'] >= count]\n",
    "\n",
    "    df = pd.merge(df, lat_lon_pairs[['lat', 'lon']], on = ['lat', 'lon'], how = 'inner')\n",
    "    return df\n",
    "\n",
    "df_sparse = filter_sparse_data(df, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e75f48a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:53.976219Z",
     "iopub.status.busy": "2025-04-12T00:37:53.975828Z",
     "iopub.status.idle": "2025-04-12T00:37:54.880161Z",
     "shell.execute_reply": "2025-04-12T00:37:54.879078Z"
    },
    "papermill": {
     "duration": 0.914674,
     "end_time": "2025-04-12T00:37:54.882438",
     "exception": false,
     "start_time": "2025-04-12T00:37:53.967764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pm25_metrics_dict = {\n",
    "    'MSE': mean_squared_error, \n",
    "    'r2 score': r2_score, \n",
    "    'MAE': mean_absolute_error,\n",
    "    'Accuracy': AQIClassifier('pm2_5')\n",
    "}\n",
    "\n",
    "pm10_metrics_dict = {\n",
    "    'MSE': mean_squared_error, \n",
    "    'r2 score': r2_score, \n",
    "    'MAE': mean_absolute_error,\n",
    "    'Accuracy': AQIClassifier('pm10')\n",
    "}\n",
    "\n",
    "pm25_evaluator = Evaluator(\n",
    "    df,\n",
    "    min_train_date,\n",
    "    max_train_date,\n",
    "    'pm2_5',\n",
    "    pm25_metrics_dict,\n",
    "    max_lookback=None\n",
    ")\n",
    "\n",
    "pm10_evaluator = Evaluator(\n",
    "    df_sparse,\n",
    "    min_train_date,\n",
    "    max_train_date,\n",
    "    'pm10',\n",
    "    pm10_metrics_dict,\n",
    "    max_lookback=None\n",
    ")\n",
    "\n",
    "pm25_evaluator2 = Evaluator(\n",
    "    df_sparse,\n",
    "    min_train_date,\n",
    "    max_train_date,\n",
    "    'pm2_5',\n",
    "    pm25_metrics_dict,\n",
    "    max_lookback=None\n",
    ")\n",
    "\n",
    "pm10_evaluator2 = Evaluator(\n",
    "    df,\n",
    "    min_train_date,\n",
    "    max_train_date,\n",
    "    'pm10',\n",
    "    pm10_metrics_dict,\n",
    "    max_lookback=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f33e6c6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:54.903300Z",
     "iopub.status.busy": "2025-04-12T00:37:54.902929Z",
     "iopub.status.idle": "2025-04-12T00:37:58.502727Z",
     "shell.execute_reply": "2025-04-12T00:37:58.501205Z"
    },
    "papermill": {
     "duration": 3.612812,
     "end_time": "2025-04-12T00:37:58.505457",
     "exception": false,
     "start_time": "2025-04-12T00:37:54.892645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('engineered_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8669b5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:58.522905Z",
     "iopub.status.busy": "2025-04-12T00:37:58.522371Z",
     "iopub.status.idle": "2025-04-12T00:37:58.567921Z",
     "shell.execute_reply": "2025-04-12T00:37:58.566688Z"
    },
    "papermill": {
     "duration": 0.056464,
     "end_time": "2025-04-12T00:37:58.570048",
     "exception": false,
     "start_time": "2025-04-12T00:37:58.513584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_value</th>\n",
       "      <th>timeOfDay</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>pm10</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>distance</th>\n",
       "      <th>bus_count</th>\n",
       "      <th>pm2_5_lag_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pm2_5_lag_7</th>\n",
       "      <th>pm10_lag_7</th>\n",
       "      <th>idw_lag_1_pm2_5</th>\n",
       "      <th>idw_lag_2_pm2_5</th>\n",
       "      <th>idw_lag_3_pm2_5</th>\n",
       "      <th>idw_lag_7_pm2_5</th>\n",
       "      <th>idw_lag_1_pm10</th>\n",
       "      <th>idw_lag_2_pm10</th>\n",
       "      <th>idw_lag_3_pm10</th>\n",
       "      <th>idw_lag_7_pm10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>481.37</td>\n",
       "      <td>522.53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.000308</td>\n",
       "      <td>...</td>\n",
       "      <td>197.253747</td>\n",
       "      <td>214.864707</td>\n",
       "      <td>197.287118</td>\n",
       "      <td>359.376438</td>\n",
       "      <td>446.796673</td>\n",
       "      <td>197.287118</td>\n",
       "      <td>231.26935</td>\n",
       "      <td>389.966421</td>\n",
       "      <td>481.86334</td>\n",
       "      <td>231.26935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>471.18</td>\n",
       "      <td>513.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.000308</td>\n",
       "      <td>...</td>\n",
       "      <td>197.253747</td>\n",
       "      <td>214.864707</td>\n",
       "      <td>197.287118</td>\n",
       "      <td>359.376438</td>\n",
       "      <td>446.796673</td>\n",
       "      <td>197.287118</td>\n",
       "      <td>231.26935</td>\n",
       "      <td>389.966421</td>\n",
       "      <td>481.86334</td>\n",
       "      <td>231.26935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>462.44</td>\n",
       "      <td>503.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.000308</td>\n",
       "      <td>...</td>\n",
       "      <td>197.253747</td>\n",
       "      <td>214.864707</td>\n",
       "      <td>197.287118</td>\n",
       "      <td>359.376438</td>\n",
       "      <td>446.796673</td>\n",
       "      <td>197.287118</td>\n",
       "      <td>231.26935</td>\n",
       "      <td>389.966421</td>\n",
       "      <td>481.86334</td>\n",
       "      <td>231.26935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>468.14</td>\n",
       "      <td>507.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.000308</td>\n",
       "      <td>...</td>\n",
       "      <td>197.253747</td>\n",
       "      <td>214.864707</td>\n",
       "      <td>197.287118</td>\n",
       "      <td>359.376438</td>\n",
       "      <td>446.796673</td>\n",
       "      <td>197.287118</td>\n",
       "      <td>231.26935</td>\n",
       "      <td>389.966421</td>\n",
       "      <td>481.86334</td>\n",
       "      <td>231.26935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>462.68</td>\n",
       "      <td>505.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.000308</td>\n",
       "      <td>...</td>\n",
       "      <td>197.253747</td>\n",
       "      <td>214.864707</td>\n",
       "      <td>197.287118</td>\n",
       "      <td>359.376438</td>\n",
       "      <td>446.796673</td>\n",
       "      <td>197.287118</td>\n",
       "      <td>231.26935</td>\n",
       "      <td>389.966421</td>\n",
       "      <td>481.86334</td>\n",
       "      <td>231.26935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_value  timeOfDay       lat       lon   pm2_5    pm10  day_of_week  \\\n",
       "0 2020-11-01        0.0  0.269231  0.809524  481.37  522.53          1.0   \n",
       "1 2020-11-01        0.0  0.307692  0.761905  471.18  513.50          1.0   \n",
       "2 2020-11-01        0.0  0.346154  0.714286  462.44  503.81          1.0   \n",
       "3 2020-11-01        0.0  0.346154  0.761905  468.14  507.55          1.0   \n",
       "4 2020-11-01        0.0  0.384615  0.714286  462.68  505.21          1.0   \n",
       "\n",
       "   distance  bus_count  pm2_5_lag_1  ...  pm2_5_lag_7  pm10_lag_7  \\\n",
       "0  0.001765        0.0   197.000308  ...   197.253747  214.864707   \n",
       "1  0.001765        0.0   197.000308  ...   197.253747  214.864707   \n",
       "2  0.001765        0.0   197.000308  ...   197.253747  214.864707   \n",
       "3  0.001765        0.0   197.000308  ...   197.253747  214.864707   \n",
       "4  0.001765        0.0   197.000308  ...   197.253747  214.864707   \n",
       "\n",
       "   idw_lag_1_pm2_5  idw_lag_2_pm2_5  idw_lag_3_pm2_5  idw_lag_7_pm2_5  \\\n",
       "0       197.287118       359.376438       446.796673       197.287118   \n",
       "1       197.287118       359.376438       446.796673       197.287118   \n",
       "2       197.287118       359.376438       446.796673       197.287118   \n",
       "3       197.287118       359.376438       446.796673       197.287118   \n",
       "4       197.287118       359.376438       446.796673       197.287118   \n",
       "\n",
       "   idw_lag_1_pm10  idw_lag_2_pm10  idw_lag_3_pm10  idw_lag_7_pm10  \n",
       "0       231.26935      389.966421       481.86334       231.26935  \n",
       "1       231.26935      389.966421       481.86334       231.26935  \n",
       "2       231.26935      389.966421       481.86334       231.26935  \n",
       "3       231.26935      389.966421       481.86334       231.26935  \n",
       "4       231.26935      389.966421       481.86334       231.26935  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da3be3f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:58.588370Z",
     "iopub.status.busy": "2025-04-12T00:37:58.587903Z",
     "iopub.status.idle": "2025-04-12T00:37:58.595277Z",
     "shell.execute_reply": "2025-04-12T00:37:58.594051Z"
    },
    "papermill": {
     "duration": 0.018319,
     "end_time": "2025-04-12T00:37:58.597626",
     "exception": false,
     "start_time": "2025-04-12T00:37:58.579307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timeOfDay',\n",
       " 'lat',\n",
       " 'lon',\n",
       " 'day_of_week',\n",
       " 'distance',\n",
       " 'bus_count',\n",
       " 'pm2_5_lag_1',\n",
       " 'pm10_lag_1',\n",
       " 'pm2_5_lag_2',\n",
       " 'pm10_lag_2',\n",
       " 'pm2_5_lag_3',\n",
       " 'pm10_lag_3',\n",
       " 'pm2_5_lag_7',\n",
       " 'pm10_lag_7',\n",
       " 'idw_lag_1_pm2_5',\n",
       " 'idw_lag_2_pm2_5',\n",
       " 'idw_lag_3_pm2_5',\n",
       " 'idw_lag_7_pm2_5',\n",
       " 'idw_lag_1_pm10',\n",
       " 'idw_lag_2_pm10',\n",
       " 'idw_lag_3_pm10',\n",
       " 'idw_lag_7_pm10']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60f0fc2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T00:37:58.620820Z",
     "iopub.status.busy": "2025-04-12T00:37:58.620429Z",
     "iopub.status.idle": "2025-04-12T02:22:43.508220Z",
     "shell.execute_reply": "2025-04-12T02:22:43.506394Z"
    },
    "papermill": {
     "duration": 6284.90851,
     "end_time": "2025-04-12T02:22:43.519401",
     "exception": false,
     "start_time": "2025-04-12T00:37:58.610891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Model XGB\n",
      "Train PM pm2_5: R2 Score 0.7859136433820467, \n",
      "               RMSE 48.02828176849066\n",
      "               MAE  34.51806205645105\n",
      "               Acc  0.6930574009895927\n",
      "        \n",
      "Test PM pm2_5: R2 Score 0.05303557564343031, \n",
      "              RMSE 98.11367177220335\n",
      "              MAE  74.64977040809585\n",
      "              Acc  0.5080732568157186\n",
      "        \n",
      "Train PM pm10: R2 Score 0.7867392181921339, \n",
      "               RMSE 52.008693122275695\n",
      "               MAE  37.35776788663118\n",
      "               Acc  0.7213188333025009\n",
      "        \n",
      "Test PM pm10: R2 Score 0.06647111930742344, \n",
      "              RMSE 106.18441564406139\n",
      "              MAE  80.73961916176759\n",
      "              Acc  0.5278156221616712\n",
      "        \n",
      "Train PM pm2_5: R2 Score 0.7881689111276394, \n",
      "               RMSE 47.84520881988315\n",
      "               MAE  34.42976916585778\n",
      "               Acc  0.6938018094206154\n",
      "        \n",
      "Test PM pm2_5: R2 Score 0.08101477313879735, \n",
      "              RMSE 97.0471048143982\n",
      "              MAE  73.54987564545453\n",
      "              Acc  0.5143903269754768\n",
      "        \n",
      "Train PM pm10: R2 Score 0.7850737879552527, \n",
      "               RMSE 52.13196593121911\n",
      "               MAE  37.41902897675351\n",
      "               Acc  0.7212436888332007\n",
      "        \n",
      "Test PM pm10: R2 Score 0.11454106635125783, \n",
      "              RMSE 102.9935025786704\n",
      "              MAE  78.51208466886504\n",
      "              Acc  0.5365311397048607\n",
      "        \n",
      "-------------------------------------------------------------------------------\n",
      "Running Model Ridge\n",
      "Train PM pm2_5: R2 Score 0.28898440484502197, \n",
      "               RMSE 87.52701496185051\n",
      "               MAE  65.00036840715438\n",
      "               Acc  0.5421264535649143\n",
      "        \n",
      "Test PM pm2_5: R2 Score 0.19226212867704529, \n",
      "              RMSE 90.61454619883963\n",
      "              MAE  68.99149087651749\n",
      "              Acc  0.5615985326404135\n",
      "        \n",
      "Train PM pm10: R2 Score 0.289275439504859, \n",
      "               RMSE 94.94478256496892\n",
      "               MAE  70.4355129203301\n",
      "               Acc  0.5720636556639094\n",
      "        \n",
      "Test PM pm10: R2 Score 0.19687448754857695, \n",
      "              RMSE 98.48920078633935\n",
      "              MAE  75.15297393627746\n",
      "              Acc  0.5604280199818347\n",
      "        \n",
      "Train PM pm2_5: R2 Score 0.290113252967902, \n",
      "               RMSE 87.5866950596937\n",
      "               MAE  65.08317674874162\n",
      "               Acc  0.5417118140895196\n",
      "        \n",
      "Test PM pm2_5: R2 Score 0.19313551206522284, \n",
      "              RMSE 90.93448666379157\n",
      "              MAE  69.30877081699407\n",
      "              Acc  0.5586682561307902\n",
      "        \n",
      "Train PM pm10: R2 Score 0.28813889433882334, \n",
      "               RMSE 94.87614778188987\n",
      "               MAE  70.34259454787434\n",
      "               Acc  0.5725053564130942\n",
      "        \n",
      "Test PM pm10: R2 Score 0.19598785225823268, \n",
      "              RMSE 98.14245579479719\n",
      "              MAE  74.81383065172162\n",
      "              Acc  0.5639329683461635\n",
      "        \n",
      "-------------------------------------------------------------------------------\n",
      "Running Model IDW\n",
      "Train PM pm2_5: R2 Score 0.9998749261817144, \n",
      "               RMSE 1.1608758013891929\n",
      "               MAE  0.8098766582745339\n",
      "               Acc  0.9897685220042712\n",
      "        \n",
      "Test PM pm2_5: R2 Score 0.16459367936264513, \n",
      "              RMSE 92.15344504892674\n",
      "              MAE  70.62042548112828\n",
      "              Acc  0.5589028152182975\n",
      "        \n",
      "Train PM pm10: R2 Score 0.999874898169514, \n",
      "               RMSE 1.259656913529985\n",
      "               MAE  0.8770068009702718\n",
      "               Acc  0.9920963379934283\n",
      "        \n",
      "Test PM pm10: R2 Score 0.16461955002044226, \n",
      "              RMSE 100.4474823570579\n",
      "              MAE  77.0194740098627\n",
      "              Acc  0.5507209355131698\n",
      "        \n",
      "Train PM pm2_5: R2 Score 0.9998762054491157, \n",
      "               RMSE 1.1566297783835169\n",
      "               MAE  0.80721614689979\n",
      "               Acc  0.9897931587339341\n",
      "        \n",
      "Test PM pm2_5: R2 Score 0.16628064141838295, \n",
      "              RMSE 92.43538652568954\n",
      "              MAE  70.87728224513492\n",
      "              Acc  0.5569084922797457\n",
      "        \n",
      "Train PM pm10: R2 Score 0.999873485768949, \n",
      "               RMSE 1.2648210959937964\n",
      "               MAE  0.8800140637180609\n",
      "               Acc  0.9921508909076112\n",
      "        \n",
      "Test PM pm10: R2 Score 0.16307432654994425, \n",
      "              RMSE 100.1311170184023\n",
      "              MAE  76.73693650139845\n",
      "              Acc  0.5534280076702888\n",
      "        \n",
      "-------------------------------------------------------------------------------\n",
      "Running Model LightGBM\n",
      "Train PM pm2_5: R2 Score 0.6976477005298432, \n",
      "               RMSE 57.076744232220406\n",
      "               MAE  41.52250035774152\n",
      "               Acc  0.6493104230162775\n",
      "        \n",
      "Test PM pm2_5: R2 Score 0.18978115457804012, \n",
      "              RMSE 90.75360119824882\n",
      "              MAE  68.70018375604484\n",
      "              Acc  0.5499819359141817\n",
      "        \n",
      "Train PM pm10: R2 Score 0.6997545524936674, \n",
      "               RMSE 61.71044213345664\n",
      "               MAE  44.86322547366241\n",
      "               Acc  0.675221772950307\n",
      "        \n",
      "Test PM pm10: R2 Score 0.1941900325034166, \n",
      "              RMSE 98.65366403952888\n",
      "              MAE  74.65029503440063\n",
      "              Acc  0.5607402361489555\n",
      "        \n",
      "Train PM pm2_5: R2 Score 0.6993257318294528, \n",
      "               RMSE 57.002215591259116\n",
      "               MAE  41.54459816451302\n",
      "               Acc  0.6487860849035827\n",
      "        \n",
      "Test PM pm2_5: R2 Score 0.19702804811936658, \n",
      "              RMSE 90.71487499844083\n",
      "              MAE  68.56192311632256\n",
      "              Acc  0.547683923705722\n",
      "        \n",
      "Train PM pm10: R2 Score 0.6965043355375742, \n",
      "               RMSE 61.94919341632914\n",
      "               MAE  44.950318559952436\n",
      "               Acc  0.6754024545276107\n",
      "        \n",
      "Test PM pm10: R2 Score 0.19059976650541566, \n",
      "              RMSE 98.47075741779098\n",
      "              MAE  74.4605085169232\n",
      "              Acc  0.5570686157352083\n",
      "        \n",
      "-------------------------------------------------------------------------------\n",
      "Running Model CatBoostRegressor\n",
      "Train PM pm2_5: R2 Score 0.7807069605735133, \n",
      "               RMSE 48.60880871558736\n",
      "               MAE  34.66626478205537\n",
      "               Acc  0.693416888880378\n",
      "        \n",
      "Test PM pm2_5: R2 Score 0.1137640514589997, \n",
      "              RMSE 94.91555209999375\n",
      "              MAE  72.33347101410315\n",
      "              Acc  0.5299169052052358\n",
      "        \n",
      "Train PM pm10: R2 Score 0.7813808307017536, \n",
      "               RMSE 52.658024509728065\n",
      "               MAE  37.575452453573774\n",
      "               Acc  0.7204260154866672\n",
      "        \n",
      "Test PM pm10: R2 Score 0.13012156291159427, \n",
      "              RMSE 102.50054745654042\n",
      "              MAE  78.00519589182883\n",
      "              Acc  0.5401907356948229\n",
      "        \n",
      "Train PM pm2_5: R2 Score 0.7829221138109579, \n",
      "               RMSE 48.43411817330511\n",
      "               MAE  34.59461549763505\n",
      "               Acc  0.6933190623430852\n",
      "        \n",
      "Test PM pm2_5: R2 Score 0.11753094866513203, \n",
      "              RMSE 95.09946208421363\n",
      "              MAE  72.5314333859681\n",
      "              Acc  0.5288090372388737\n",
      "        \n",
      "Train PM pm10: R2 Score 0.779515812357394, \n",
      "               RMSE 52.80172791901881\n",
      "               MAE  37.62278396969197\n",
      "               Acc  0.7206944470436473\n",
      "        \n",
      "Test PM pm10: R2 Score 0.13514432793520226, \n",
      "              RMSE 101.78820007577971\n",
      "              MAE  77.53987400310743\n",
      "              Acc  0.5423394380679766\n",
      "        \n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_list = {\n",
    "    \"XGB\" : [XGBRegressor, {}],\n",
    "    \"Ridge\" : [Ridge, {}],\n",
    "    \"IDW\" : [IDW, {'leafsize': 50, 'k': 20, 'power': 0.25}],\n",
    "    \"LightGBM\" : [LGBMRegressor, {'verbose':0}],\n",
    "    \"CatBoostRegressor\": [CatBoostRegressor, {'verbose' : 0}],\n",
    "    # \"RandomForest\" : [RandomForestRegressor, {'n_estimators' : 50}],\n",
    "}\n",
    "\n",
    "for model_name, [model, params] in model_list.items():\n",
    "    print(f\"Running Model {model_name}\")\n",
    "    model_wrapper = Model(model, params, target='pm2_5')\n",
    "    pm25_evaluator.evaluate(\n",
    "        model_wrapper, daily=False, save=True, model_name=model_name, verbose=True\n",
    "    )\n",
    "\n",
    "    model_wrapper = Model(model, params, target='pm10')\n",
    "    pm10_evaluator.evaluate(\n",
    "        model_wrapper, daily=False, save=True, model_name=model_name, verbose=True\n",
    "    )\n",
    "\n",
    "    model_wrapper = Model(model, params, target='pm2_5')\n",
    "    pm25_evaluator2.evaluate(\n",
    "        model_wrapper, daily=False, save=True, model_name=model_name, verbose=True\n",
    "    )\n",
    "\n",
    "    model_wrapper = Model(model, params, target='pm10')\n",
    "    pm10_evaluator2.evaluate(\n",
    "        model_wrapper, daily=False, save=True, model_name=model_name, verbose=True\n",
    "    )\n",
    "\n",
    "    print(\"-------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedda0f4",
   "metadata": {
    "papermill": {
     "duration": 0.008795,
     "end_time": "2025-04-12T02:22:43.537438",
     "exception": false,
     "start_time": "2025-04-12T02:22:43.528643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 226700844,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6335.558225,
   "end_time": "2025-04-12T02:22:46.278939",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-12T00:37:10.720714",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
